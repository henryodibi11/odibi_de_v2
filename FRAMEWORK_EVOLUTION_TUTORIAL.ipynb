{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 odibi_de_v2 Framework Evolution Tutorial\n",
    "## From v1.x (Industry-Specific) to v2.0 (Universal)\n",
    "\n",
    "**Version:** 2.0  \n",
    "**Last Updated:** October 29, 2025  \n",
    "**Target Audience:** Data Engineers, Analytics Engineers, ML Engineers\n",
    "\n",
    "---\n",
    "\n",
    "## 📑 Table of Contents\n",
    "\n",
    "1. [Introduction: What Changed and Why](#1-introduction)\n",
    "2. [Architecture Overview](#2-architecture)\n",
    "3. [Step-by-Step Walkthrough](#3-walkthrough)\n",
    "4. [Examples by Industry](#4-examples)\n",
    "5. [Troubleshooting Guide](#5-troubleshooting)\n",
    "6. [Quick Reference](#6-reference)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction: What Changed and Why {#1-introduction}\n",
    "\n",
    "### 1.1 The Evolution Story\n",
    "\n",
    "**v1.x - The Ingredion Era:**\n",
    "- Built specifically for manufacturing use cases\n",
    "- Hardcoded entity columns: `plant`, `asset`\n",
    "- Single input/output per transformation\n",
    "- Manual orchestrator instantiation\n",
    "- Great for Ingredion, limiting for other domains\n",
    "\n",
    "**v2.0 - Universal Framework:**\n",
    "- Works for ANY industry: manufacturing, retail, finance, healthcare, ML\n",
    "- Generic entity system: `entity_1`, `entity_2`, `entity_3`\n",
    "- Multiple inputs/constants/outputs (JSON-based)\n",
    "- One-command execution: `run_project()`\n",
    "- Project scaffolding: `initialize_project()`\n",
    "- Full backward compatibility\n",
    "\n",
    "### 1.2 Why the Refactoring?\n",
    "\n",
    "**Pain Points in v1.x:**\n",
    "```python\n",
    "# ❌ Old way - Too specific\n",
    "orchestrator = IngredionProjectOrchestrator(\n",
    "    project=\"Energy Efficiency\",\n",
    "    env=\"qat\",\n",
    "    # Hardcoded for manufacturing only\n",
    ")\n",
    "result = orchestrator.run(\n",
    "    repo_path=\"/path/to/repo\",\n",
    "    layer_order=[\"Silver_1\", \"Gold_1\"],\n",
    "    cache_plan={...},\n",
    "    max_workers=4\n",
    ")\n",
    "```\n",
    "\n",
    "**v2.0 Solution:**\n",
    "```python\n",
    "# ✅ New way - Universal and simple\n",
    "from odibi_de_v2 import run_project\n",
    "\n",
    "result = run_project(project=\"Energy Efficiency\", env=\"qat\")\n",
    "```\n",
    "\n",
    "### 1.3 Key Benefits\n",
    "\n",
    "| Feature | v1.x | v2.0 | Benefit |\n",
    "|---------|------|------|----------|\n",
    "| **Domain Support** | Manufacturing only | Any domain | Reusability |\n",
    "| **Entity Model** | `plant`, `asset` | `entity_1/2/3` | Flexibility |\n",
    "| **Inputs** | Single table | Multiple (JSON) | Complex workflows |\n",
    "| **Constants** | None | JSON object | Parameterization |\n",
    "| **Outputs** | Single table | Multiple (JSON) | Multi-target pipelines |\n",
    "| **Execution** | Manual class | `run_project()` | Simplicity |\n",
    "| **Setup** | Manual | `initialize_project()` | Speed |\n",
    "| **Lines of Code** | ~50 lines | 1 line | Productivity |\n",
    "\n",
    "### 1.4 Backward Compatibility\n",
    "\n",
    "✅ All v1.x projects continue to work  \n",
    "✅ Legacy view `TransformationConfig_Legacy` provided  \n",
    "✅ Gradual migration path  \n",
    "✅ No breaking changes to transformation functions  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Architecture Overview {#2-architecture}\n",
    "\n",
    "### 2.1 System Architecture\n",
    "\n",
    "```mermaid\n",
    "graph TB\n",
    "    subgraph \"Configuration Layer\"\n",
    "        A[TransformationRegistry SQL Table]\n",
    "        B[Project Manifest JSON]\n",
    "        C[IngestionSourceConfig]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Orchestration Layer\"\n",
    "        D[run_project API]\n",
    "        E[TransformationRunner]\n",
    "        F[Layer Executor]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Execution Layer\"\n",
    "        G[Bronze Ingestion]\n",
    "        H[Silver Transformations]\n",
    "        I[Gold Aggregations]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Storage Layer\"\n",
    "        J[Delta Lake]\n",
    "        K[Azure Blob Storage]\n",
    "        L[SQL Database]\n",
    "    end\n",
    "    \n",
    "    A --> D\n",
    "    B --> D\n",
    "    C --> G\n",
    "    D --> E\n",
    "    E --> F\n",
    "    F --> G\n",
    "    F --> H\n",
    "    F --> I\n",
    "    G --> J\n",
    "    H --> J\n",
    "    I --> J\n",
    "    J --> K\n",
    "    A --> L\n",
    "```\n",
    "\n",
    "### 2.2 TransformationRegistry Schema\n",
    "\n",
    "**The Heart of Configuration**\n",
    "\n",
    "```sql\n",
    "CREATE TABLE TransformationRegistry (\n",
    "    -- Identity\n",
    "    transformation_id VARCHAR(100) PRIMARY KEY,     -- Unique ID\n",
    "    transformation_group_id VARCHAR(100),           -- Logical grouping\n",
    "    \n",
    "    -- Scoping\n",
    "    project VARCHAR(100) NOT NULL,                  -- Project name\n",
    "    environment VARCHAR(20) NOT NULL,               -- qat, prod, dev\n",
    "    \n",
    "    -- Execution Control\n",
    "    layer VARCHAR(50) NOT NULL,                     -- Bronze, Silver_1, Gold_1\n",
    "    step INT NOT NULL DEFAULT 1,                    -- Execution order within layer\n",
    "    enabled BIT NOT NULL DEFAULT 1,                 -- On/off switch\n",
    "    \n",
    "    -- Generic Entity Hierarchy (Domain-Agnostic)\n",
    "    entity_1 VARCHAR(100),                          -- Top-level entity\n",
    "    entity_2 VARCHAR(100),                          -- Mid-level entity\n",
    "    entity_3 VARCHAR(100),                          -- Detail-level entity\n",
    "    \n",
    "    -- Transformation Logic\n",
    "    module VARCHAR(255) NOT NULL,                   -- Python module path\n",
    "    function VARCHAR(255) NOT NULL,                 -- Function name\n",
    "    \n",
    "    -- Flexible I/O (JSON)\n",
    "    inputs NVARCHAR(MAX),                           -- [\"table1\", \"table2\"]\n",
    "    constants NVARCHAR(MAX),                        -- {\"threshold\": 100}\n",
    "    outputs NVARCHAR(MAX),                          -- [{\"table\": \"...\", \"mode\": \"...\"}]\n",
    "    \n",
    "    -- Metadata\n",
    "    description NVARCHAR(500),\n",
    "    created_at DATETIME,\n",
    "    updated_at DATETIME\n",
    ");\n",
    "```\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "1. **Generic Entities**: Adapt to any domain\n",
    "   - Manufacturing: `entity_1=plant`, `entity_2=asset`, `entity_3=equipment`\n",
    "   - Retail: `entity_1=region`, `entity_2=store`, `entity_3=department`\n",
    "   - Finance: `entity_1=business_unit`, `entity_2=product`, `entity_3=account_type`\n",
    "\n",
    "2. **JSON Fields**: Maximum flexibility\n",
    "   - `inputs`: Array of table names or query objects\n",
    "   - `constants`: Parameters passed to transformation function\n",
    "   - `outputs`: Array of output configurations\n",
    "\n",
    "3. **Layer-Based Execution**: Medallion architecture\n",
    "   - Layers run in sequence: Bronze → Silver → Gold\n",
    "   - Within layer, transformations run by `step` order\n",
    "   - Parallel execution within same step\n",
    "\n",
    "### 2.3 Manifest System\n",
    "\n",
    "**Project-Level Configuration**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"project_name\": \"Energy Efficiency\",\n",
    "  \"project_type\": \"manufacturing\",\n",
    "  \"layer_order\": [\"Bronze\", \"Silver_1\", \"Silver_2\", \"Gold_1\", \"Gold_2\"],\n",
    "  \"entity_labels\": {\n",
    "    \"entity_1\": \"plant\",\n",
    "    \"entity_2\": \"asset\",\n",
    "    \"entity_3\": \"equipment\"\n",
    "  },\n",
    "  \"cache_plan\": {\n",
    "    \"Gold_1\": [\"combined_dryers\", \"combined_boilers\"]\n",
    "  },\n",
    "  \"environments\": [\"qat\", \"prod\"],\n",
    "  \"default_env\": \"qat\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Manifest Benefits:**\n",
    "- Centralized project configuration\n",
    "- Version-controlled (Git)\n",
    "- Self-documenting\n",
    "- Environment-specific overrides\n",
    "\n",
    "### 2.4 Component Interaction Flow\n",
    "\n",
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant User\n",
    "    participant API as run_project()\n",
    "    participant Manifest\n",
    "    participant Registry as TransformationRegistry\n",
    "    participant Runner as TransformationRunner\n",
    "    participant Spark\n",
    "    participant Delta as Delta Lake\n",
    "    \n",
    "    User->>API: run_project(\"Energy Efficiency\", \"qat\")\n",
    "    API->>Manifest: Load manifest.json\n",
    "    Manifest-->>API: layer_order, entity_labels, cache_plan\n",
    "    \n",
    "    loop For each layer in layer_order\n",
    "        API->>Registry: SELECT * WHERE project='...' AND layer='...'\n",
    "        Registry-->>API: transformation configs\n",
    "        API->>Runner: Execute transformations\n",
    "        \n",
    "        loop For each transformation\n",
    "            Runner->>Spark: Import module.function\n",
    "            Runner->>Spark: Execute with inputs/constants\n",
    "            Spark->>Delta: Write outputs\n",
    "            Delta-->>Runner: Success\n",
    "        end\n",
    "        \n",
    "        Runner-->>API: Layer complete\n",
    "    end\n",
    "    \n",
    "    API-->>User: {status: 'SUCCESS', layers_run: [...]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Step-by-Step Walkthrough {#3-walkthrough}\n",
    "\n",
    "### Cell 1: Import the New API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the two main functions you'll use\n",
    "from odibi_de_v2 import run_project, initialize_project\n",
    "\n",
    "# Optional: Import utilities for health checks and helpers\n",
    "from odibi_de_v2.utils import quick_health_check, print_project_summary\n",
    "from odibi_de_v2.config import TransformationRegistryUI\n",
    "\n",
    "print(\"✅ odibi_de_v2 v2.0 imported successfully!\")\n",
    "print(\"\\nMain functions available:\")\n",
    "print(\"  - initialize_project(name, type): Create new project\")\n",
    "print(\"  - run_project(project, env): Run pipeline\")\n",
    "print(\"\\nHelper utilities:\")\n",
    "print(\"  - quick_health_check(): Validate configuration\")\n",
    "print(\"  - print_project_summary(): View project status\")\n",
    "print(\"  - TransformationRegistryUI(): Interactive config editor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2: Understanding TransformationRegistry Table\n",
    "\n",
    "**The TransformationRegistry is where all transformation logic is configured.**\n",
    "\n",
    "Let's explore the schema and see example records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to your SQL provider (replace with your actual connection)\n",
    "from your_sql_provider import get_sql_provider\n",
    "\n",
    "sql_provider = get_sql_provider()\n",
    "\n",
    "# View the schema\n",
    "print(\"📋 TransformationRegistry Schema:\")\n",
    "print(\"\"\"\n",
    "Key Fields:\n",
    "  • transformation_id: Unique identifier (e.g., 'energy-argo-boilers-silver')\n",
    "  • project: Project name (e.g., 'Energy Efficiency')\n",
    "  • environment: qat, prod, dev\n",
    "  • layer: Bronze, Silver_1, Silver_2, Gold_1, etc.\n",
    "  • entity_1/2/3: Generic hierarchy (adapt to your domain)\n",
    "  • module: Python module path (e.g., 'silver.functions')\n",
    "  • function: Function name (e.g., 'process_argo_boilers')\n",
    "  • inputs: JSON array [\"table1\", \"table2\"]\n",
    "  • constants: JSON object {\"threshold\": 100}\n",
    "  • outputs: JSON array [{\"table\": \"...\", \"mode\": \"overwrite\"}]\n",
    "\"\"\")\n",
    "\n",
    "# Query some example records\n",
    "query = \"\"\"\n",
    "SELECT TOP 3\n",
    "    transformation_id,\n",
    "    project,\n",
    "    layer,\n",
    "    entity_1,\n",
    "    entity_2,\n",
    "    function,\n",
    "    inputs,\n",
    "    outputs\n",
    "FROM TransformationRegistry\n",
    "WHERE enabled = 1\n",
    "ORDER BY layer, step\n",
    "\"\"\"\n",
    "\n",
    "# Execute query\n",
    "# df = sql_provider.execute_query(query)\n",
    "# display(df)\n",
    "\n",
    "print(\"\\n💡 Tip: Use TransformationRegistryUI() to edit configs interactively!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 3: Understanding Project Manifests\n",
    "\n",
    "**Manifests define project-level configuration in JSON format.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example manifest structure\n",
    "example_manifest = {\n",
    "    \"project_name\": \"Energy Efficiency\",\n",
    "    \"project_type\": \"manufacturing\",\n",
    "    \"description\": \"Manufacturing energy analytics pipeline\",\n",
    "    \"version\": \"1.0.0\",\n",
    "    \n",
    "    # Layer execution order\n",
    "    \"layer_order\": [\"Bronze\", \"Silver_1\", \"Silver_2\", \"Gold_1\", \"Gold_2\"],\n",
    "    \n",
    "    # Entity labels (domain-specific naming)\n",
    "    \"entity_labels\": {\n",
    "        \"entity_1\": \"plant\",\n",
    "        \"entity_2\": \"asset\",\n",
    "        \"entity_3\": \"equipment\"\n",
    "    },\n",
    "    \n",
    "    # Caching strategy\n",
    "    \"cache_plan\": {\n",
    "        \"Gold_1\": [\"combined_dryers\", \"combined_boilers\"]\n",
    "    },\n",
    "    \n",
    "    # Environments\n",
    "    \"environments\": [\"qat\", \"prod\"],\n",
    "    \"default_env\": \"qat\"\n",
    "}\n",
    "\n",
    "print(\"📄 Example Project Manifest:\")\n",
    "print(json.dumps(example_manifest, indent=2))\n",
    "\n",
    "print(\"\\n🔑 Key Manifest Components:\")\n",
    "print(\"  1. layer_order: Defines execution sequence\")\n",
    "print(\"  2. entity_labels: Maps generic entities to domain terms\")\n",
    "print(\"  3. cache_plan: Specifies which tables to cache per layer\")\n",
    "print(\"  4. environments: Supported environments (qat, prod, dev)\")\n",
    "\n",
    "print(\"\\n💡 Manifests are auto-generated by initialize_project()!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 4: How to Create New Projects with initialize_project()\n",
    "\n",
    "**The fastest way to start a new data pipeline.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odibi_de_v2 import initialize_project\n",
    "from odibi_de_v2.project import ProjectType\n",
    "\n",
    "# Example 1: Manufacturing Project\n",
    "result_manufacturing = initialize_project(\n",
    "    project_name=\"Plant Reliability\",\n",
    "    project_type=ProjectType.MANUFACTURING,\n",
    "    description=\"Predictive maintenance and reliability analytics\"\n",
    ")\n",
    "\n",
    "print(\"✅ Manufacturing project created!\")\n",
    "print(f\"   Path: {result_manufacturing['project_path']}\")\n",
    "print(f\"   Manifest: {result_manufacturing['manifest_path']}\")\n",
    "\n",
    "# Example 2: Analytics Project\n",
    "result_analytics = initialize_project(\n",
    "    project_name=\"Customer Churn\",\n",
    "    project_type=ProjectType.ANALYTICS,\n",
    "    description=\"Customer churn prediction pipeline\"\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Analytics project created!\")\n",
    "print(f\"   Path: {result_analytics['project_path']}\")\n",
    "\n",
    "# Example 3: ML Pipeline\n",
    "result_ml = initialize_project(\n",
    "    project_name=\"Sales Forecasting\",\n",
    "    project_type=ProjectType.ML_PIPELINE,\n",
    "    description=\"Sales forecasting with ML models\"\n",
    ")\n",
    "\n",
    "print(\"\\n✅ ML Pipeline project created!\")\n",
    "print(f\"   Path: {result_ml['project_path']}\")\n",
    "\n",
    "print(\"\"\"\n",
    "\\n📁 Project Structure Created:\n",
    "project_name/\n",
    "├── manifest.json              # Project configuration\n",
    "├── transformations/           # Transformation modules\n",
    "│   ├── bronze/\n",
    "│   ├── silver/\n",
    "│   └── gold/\n",
    "├── sql/                       # SQL scripts\n",
    "│   └── ddl/\n",
    "├── notebooks/                 # Databricks notebooks\n",
    "├── config/                    # Config files\n",
    "├── tests/                     # Unit tests\n",
    "└── README.md                  # Auto-generated documentation\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n💡 Next step: Add transformations to TransformationRegistry table!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 5: How to Run Projects with run_project()\n",
    "\n",
    "**One command to rule them all.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odibi_de_v2 import run_project\n",
    "\n",
    "# Example 1: Run entire pipeline (all layers)\n",
    "print(\"🚀 Example 1: Full Pipeline Execution\")\n",
    "result = run_project(\n",
    "    project=\"Energy Efficiency\",\n",
    "    env=\"qat\"\n",
    ")\n",
    "print(f\"Status: {result['status']}\")\n",
    "print(f\"Layers run: {result['layers_run']}\")\n",
    "print(f\"Duration: {result['duration_seconds']:.2f}s\")\n",
    "\n",
    "# Example 2: Run specific layers only\n",
    "print(\"\\n🎯 Example 2: Target Specific Layers\")\n",
    "result = run_project(\n",
    "    project=\"Energy Efficiency\",\n",
    "    env=\"qat\",\n",
    "    target_layers=[\"Silver_1\", \"Gold_1\"]  # Only these layers\n",
    ")\n",
    "print(f\"Layers run: {result['layers_run']}\")\n",
    "\n",
    "# Example 3: With logging and caching\n",
    "print(\"\\n📊 Example 3: Advanced Options\")\n",
    "result = run_project(\n",
    "    project=\"Energy Efficiency\",\n",
    "    env=\"qat\",\n",
    "    log_level=\"INFO\",\n",
    "    save_logs=True,\n",
    "    cache_plan={\"Gold_1\": [\"combined_dryers\"]}  # Cache specific tables\n",
    ")\n",
    "\n",
    "# Example 4: Custom authentication\n",
    "print(\"\\n🔐 Example 4: Custom Authentication\")\n",
    "\n",
    "def custom_auth_provider(env, repo_path, logger_metadata):\n",
    "    \"\"\"Custom authentication logic.\"\"\"\n",
    "    from pyspark.sql import SparkSession\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    sql_provider = get_sql_provider()  # Your SQL provider\n",
    "    return {\"spark\": spark, \"sql_provider\": sql_provider}\n",
    "\n",
    "result = run_project(\n",
    "    project=\"Energy Efficiency\",\n",
    "    env=\"qat\",\n",
    "    auth_provider=custom_auth_provider\n",
    ")\n",
    "\n",
    "# Example 5: Dry run (validation only)\n",
    "print(\"\\n✅ Example 5: Validation Mode\")\n",
    "result = run_project(\n",
    "    project=\"Energy Efficiency\",\n",
    "    env=\"qat\",\n",
    "    dry_run=True  # Check config without executing\n",
    ")\n",
    "print(f\"Validation status: {result['status']}\")\n",
    "print(f\"Transformations found: {result['transformation_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 6: Working with the Config UI\n",
    "\n",
    "**Interactive configuration editor for TransformationRegistry.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odibi_de_v2.config import TransformationRegistryUI, TransformationRegistryBrowser\n",
    "\n",
    "# Create new transformation config interactively\n",
    "print(\"🎨 Interactive Config Editor\")\n",
    "ui = TransformationRegistryUI(\n",
    "    project=\"Energy Efficiency\",\n",
    "    env=\"qat\"\n",
    ")\n",
    "\n",
    "# This will render an interactive form\n",
    "# ui.render()\n",
    "\n",
    "print(\"\"\"\n",
    "Features:\n",
    "  ✅ Visual field editor\n",
    "  ✅ JSON validation (inputs, constants, outputs)\n",
    "  ✅ Auto-generate SQL INSERT statement\n",
    "  ✅ Copy to clipboard\n",
    "  ✅ Pre-filled templates\n",
    "\"\"\")\n",
    "\n",
    "# Browse existing configurations\n",
    "print(\"\\n📚 Browse Existing Configs\")\n",
    "browser = TransformationRegistryBrowser(\n",
    "    sql_provider=sql_provider,\n",
    "    project=\"Energy Efficiency\",\n",
    "    env=\"qat\"\n",
    ")\n",
    "\n",
    "# This will render a filterable table\n",
    "# browser.render()\n",
    "\n",
    "print(\"\"\"\n",
    "Features:\n",
    "  ✅ Filter by layer, entity, enabled status\n",
    "  ✅ Search transformations\n",
    "  ✅ Quick edit/delete\n",
    "  ✅ Export to CSV/JSON\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 7: Migration from Old to New\n",
    "\n",
    "**Step-by-step migration guide for v1.x projects.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIGRATION WORKFLOW\n",
    "print(\"📋 Migration Checklist:\\n\")\n",
    "\n",
    "# Step 1: Create TransformationRegistry table\n",
    "print(\"✅ Step 1: Create TransformationRegistry Table\")\n",
    "ddl_script = \"\"\"\n",
    "-- Run this SQL script\n",
    "CREATE TABLE IF NOT EXISTS TransformationRegistry (\n",
    "    transformation_id VARCHAR(100) PRIMARY KEY,\n",
    "    project VARCHAR(100) NOT NULL,\n",
    "    environment VARCHAR(20) NOT NULL,\n",
    "    layer VARCHAR(50) NOT NULL,\n",
    "    entity_1 VARCHAR(100),\n",
    "    entity_2 VARCHAR(100),\n",
    "    module VARCHAR(255) NOT NULL,\n",
    "    function VARCHAR(255) NOT NULL,\n",
    "    inputs NVARCHAR(MAX),\n",
    "    constants NVARCHAR(MAX),\n",
    "    outputs NVARCHAR(MAX),\n",
    "    -- ... (see sql/ddl/01_transformation_registry.sql)\n",
    ");\n",
    "\"\"\"\n",
    "print(ddl_script)\n",
    "\n",
    "# Step 2: Migrate data from old TransformationConfig\n",
    "print(\"\\n✅ Step 2: Migrate Existing Data\")\n",
    "migration_sql = \"\"\"\n",
    "INSERT INTO TransformationRegistry (\n",
    "    transformation_id,\n",
    "    project,\n",
    "    environment,\n",
    "    layer,\n",
    "    entity_1,\n",
    "    entity_2,\n",
    "    module,\n",
    "    function,\n",
    "    inputs,\n",
    "    outputs\n",
    ")\n",
    "SELECT\n",
    "    'energy-' + LOWER(REPLACE(plant + '-' + asset, ' ', '-')) + '-' + layer,\n",
    "    project,\n",
    "    env AS environment,\n",
    "    layer,\n",
    "    plant AS entity_1,\n",
    "    asset AS entity_2,\n",
    "    module,\n",
    "    function,\n",
    "    JSON_QUERY('[' + QUOTENAME(input_table, '\"') + ']'),\n",
    "    JSON_QUERY('[{\"table\":\"' + target_table + '\",\"mode\":\"overwrite\"}]')\n",
    "FROM TransformationConfig\n",
    "WHERE project = 'energy efficiency';\n",
    "\"\"\"\n",
    "print(migration_sql)\n",
    "\n",
    "# Step 3: Create manifest\n",
    "print(\"\\n✅ Step 3: Create Project Manifest\")\n",
    "print(\"# Use initialize_project() or create manually\")\n",
    "print(\"result = initialize_project('Energy Efficiency', 'manufacturing')\")\n",
    "\n",
    "# Step 4: Update code\n",
    "print(\"\\n✅ Step 4: Update Orchestration Code\")\n",
    "print(\"\"\"# Before (v1.x):\n",
    "orchestrator = IngredionProjectOrchestrator(...)\n",
    "orchestrator.run(...)\n",
    "\n",
    "# After (v2.0):\n",
    "run_project(project='Energy Efficiency', env='qat')\n",
    "\"\"\")\n",
    "\n",
    "# Step 5: Test\n",
    "print(\"\\n✅ Step 5: Test\")\n",
    "print(\"run_project(project='Energy Efficiency', env='qat', target_layers=['Bronze'])\")\n",
    "\n",
    "print(\"\\n🎉 Migration complete! See MIGRATION_GUIDE.md for details.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 8: Advanced Patterns\n",
    "\n",
    "**Custom auth, multi-environment, caching strategies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADVANCED PATTERN 1: Multi-Environment Deployment\n",
    "print(\"🌍 Pattern 1: Multi-Environment Deployment\\n\")\n",
    "\n",
    "environments = [\"dev\", \"qat\", \"prod\"]\n",
    "\n",
    "for env in environments:\n",
    "    print(f\"Deploying to {env}...\")\n",
    "    result = run_project(\n",
    "        project=\"Customer Churn\",\n",
    "        env=env,\n",
    "        target_layers=[\"Silver_1\"],  # Deploy incrementally\n",
    "        dry_run=(env == \"prod\")  # Validate prod before running\n",
    "    )\n",
    "    print(f\"  {env}: {result['status']}\\n\")\n",
    "\n",
    "# ADVANCED PATTERN 2: Smart Caching\n",
    "print(\"💾 Pattern 2: Layer-Specific Caching\\n\")\n",
    "\n",
    "cache_strategy = {\n",
    "    \"Silver_1\": [],  # No caching for Silver\n",
    "    \"Gold_1\": [\"large_aggregation_table\"],  # Cache expensive tables\n",
    "    \"Gold_2\": [\"kpi_summary\", \"reporting_table\"]\n",
    "}\n",
    "\n",
    "result = run_project(\n",
    "    project=\"Energy Efficiency\",\n",
    "    env=\"qat\",\n",
    "    cache_plan=cache_strategy\n",
    ")\n",
    "\n",
    "# ADVANCED PATTERN 3: Custom Auth with Secrets\n",
    "print(\"\\n🔐 Pattern 3: Custom Authentication with Azure Key Vault\\n\")\n",
    "\n",
    "def azure_keyvault_auth(env, repo_path, logger_metadata):\n",
    "    \"\"\"Fetch credentials from Azure Key Vault.\"\"\"\n",
    "    from azure.keyvault.secrets import SecretClient\n",
    "    from azure.identity import DefaultAzureCredential\n",
    "    from pyspark.sql import SparkSession\n",
    "    \n",
    "    # Get secrets\n",
    "    credential = DefaultAzureCredential()\n",
    "    client = SecretClient(\n",
    "        vault_url=\"https://my-vault.vault.azure.net/\",\n",
    "        credential=credential\n",
    "    )\n",
    "    \n",
    "    db_password = client.get_secret(f\"db-password-{env}\").value\n",
    "    \n",
    "    # Create Spark session with secrets\n",
    "    spark = SparkSession.builder \\\n",
    "        .config(\"spark.sql.password\", db_password) \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    sql_provider = get_sql_provider(password=db_password)\n",
    "    \n",
    "    return {\"spark\": spark, \"sql_provider\": sql_provider}\n",
    "\n",
    "# Use custom auth\n",
    "# result = run_project(\n",
    "#     project=\"Secure Project\",\n",
    "#     env=\"prod\",\n",
    "#     auth_provider=azure_keyvault_auth\n",
    "# )\n",
    "\n",
    "# ADVANCED PATTERN 4: Parameterized Transformations\n",
    "print(\"\\n⚙️ Pattern 4: Dynamic Constants per Environment\\n\")\n",
    "\n",
    "# In TransformationRegistry, use env-specific constants:\n",
    "constants_example = {\n",
    "    \"qat\": {\"threshold\": 100, \"sample_rate\": 0.1},\n",
    "    \"prod\": {\"threshold\": 1000, \"sample_rate\": 1.0}\n",
    "}\n",
    "\n",
    "print(f\"QAT constants: {constants_example['qat']}\")\n",
    "print(f\"PROD constants: {constants_example['prod']}\")\n",
    "\n",
    "# ADVANCED PATTERN 5: Incremental Layers\n",
    "print(\"\\n📈 Pattern 5: Incremental Layer Execution\\n\")\n",
    "\n",
    "layers_to_run = [\"Bronze\", \"Silver_1\"]\n",
    "\n",
    "# First run: Bronze + Silver_1\n",
    "result = run_project(\n",
    "    project=\"Energy Efficiency\",\n",
    "    env=\"qat\",\n",
    "    target_layers=layers_to_run\n",
    ")\n",
    "\n",
    "if result['status'] == 'SUCCESS':\n",
    "    # Second run: Add Gold_1\n",
    "    layers_to_run.append(\"Gold_1\")\n",
    "    result = run_project(\n",
    "        project=\"Energy Efficiency\",\n",
    "        env=\"qat\",\n",
    "        target_layers=[\"Gold_1\"]  # Only new layer\n",
    "    )\n",
    "\n",
    "print(\"\\n💡 See docs/advanced_patterns.md for more examples!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Examples by Industry {#4-examples}\n",
    "\n",
    "### 4.1 Manufacturing: Energy Efficiency\n",
    "\n",
    "**Use Case:** Track energy consumption across plants and assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manufacturing Example: Energy Efficiency\n",
    "print(\"🏭 Manufacturing Example: Energy Efficiency\\n\")\n",
    "\n",
    "# Entity mapping for manufacturing\n",
    "entity_mapping = {\n",
    "    \"entity_1\": \"plant\",      # Argo, Cedar Rapids, Winston Salem\n",
    "    \"entity_2\": \"asset\",      # Boilers, Dryers, Compressors\n",
    "    \"entity_3\": \"equipment\"   # Individual equipment IDs\n",
    "}\n",
    "\n",
    "print(\"Entity Hierarchy:\")\n",
    "print(f\"  {entity_mapping['entity_1']} → {entity_mapping['entity_2']} → {entity_mapping['entity_3']}\")\n",
    "print(f\"  Example: Argo → Boiler 6,7,8 → Boiler #7\\n\")\n",
    "\n",
    "# Sample TransformationRegistry record\n",
    "sample_config = {\n",
    "    \"transformation_id\": \"energy-argo-boilers-silver\",\n",
    "    \"project\": \"energy efficiency\",\n",
    "    \"environment\": \"qat\",\n",
    "    \"layer\": \"Silver_1\",\n",
    "    \"entity_1\": \"Argo\",\n",
    "    \"entity_2\": \"Boiler 6,7,8,10\",\n",
    "    \"module\": \"silver.functions\",\n",
    "    \"function\": \"process_argo_boilers\",\n",
    "    \"inputs\": '[\"qat_energy_efficiency.argo_boilers_bronze\"]',\n",
    "    \"outputs\": '[{\"table\": \"qat_energy_efficiency.argo_boilers_silver\", \"mode\": \"overwrite\"}]'\n",
    "}\n",
    "\n",
    "print(\"Sample Configuration:\")\n",
    "for key, value in sample_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Run the pipeline\n",
    "print(\"\\n🚀 Running Energy Efficiency pipeline...\")\n",
    "result = run_project(\n",
    "    project=\"Energy Efficiency\",\n",
    "    env=\"qat\",\n",
    "    target_layers=[\"Bronze\", \"Silver_1\", \"Gold_1\"]\n",
    ")\n",
    "\n",
    "print(f\"\\nResult: {result['status']}\")\n",
    "print(f\"Layers processed: {result['layers_run']}\")\n",
    "print(f\"Duration: {result['duration_seconds']:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Analytics: Customer Churn\n",
    "\n",
    "**Use Case:** Predict customer churn using behavioral features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analytics Example: Customer Churn\n",
    "print(\"📊 Analytics Example: Customer Churn\\n\")\n",
    "\n",
    "# Entity mapping for analytics\n",
    "entity_mapping = {\n",
    "    \"entity_1\": \"region\",      # North America, Europe, Asia\n",
    "    \"entity_2\": \"segment\",     # Retail, Enterprise, SMB\n",
    "    \"entity_3\": \"channel\"      # Online, In-store, Partner\n",
    "}\n",
    "\n",
    "print(\"Entity Hierarchy:\")\n",
    "print(f\"  {entity_mapping['entity_1']} → {entity_mapping['entity_2']} → {entity_mapping['entity_3']}\")\n",
    "print(f\"  Example: North America → Retail → Online\\n\")\n",
    "\n",
    "# Sample TransformationRegistry record\n",
    "sample_config = {\n",
    "    \"transformation_id\": \"churn-features-silver\",\n",
    "    \"project\": \"customer churn\",\n",
    "    \"environment\": \"qat\",\n",
    "    \"layer\": \"Silver_1\",\n",
    "    \"entity_1\": \"North America\",\n",
    "    \"entity_2\": \"Retail\",\n",
    "    \"entity_3\": \"Online\",\n",
    "    \"module\": \"churn.features\",\n",
    "    \"function\": \"calculate_customer_features\",\n",
    "    \"inputs\": '[\"qat_churn.customer_transactions_bronze\", \"qat_churn.customer_profile_bronze\"]',\n",
    "    \"constants\": '{\"lookback_days\": 90, \"min_transactions\": 5}',\n",
    "    \"outputs\": '[{\"table\": \"qat_churn.customer_features_silver\", \"mode\": \"overwrite\"}]'\n",
    "}\n",
    "\n",
    "print(\"Sample Configuration:\")\n",
    "for key, value in sample_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Sample transformation function\n",
    "print(\"\\n📝 Sample Transformation Function:\")\n",
    "sample_function = '''\n",
    "def calculate_customer_features(spark=None, inputs=None, constants=None, outputs=None, **kwargs):\n",
    "    \"\"\"Calculate customer behavior features.\"\"\"\n",
    "    from pyspark.sql import functions as F\n",
    "    \n",
    "    # Read inputs\n",
    "    transactions = spark.table(inputs[0])\n",
    "    profiles = spark.table(inputs[1])\n",
    "    \n",
    "    # Get constants\n",
    "    lookback_days = constants.get('lookback_days', 90)\n",
    "    min_transactions = constants.get('min_transactions', 5)\n",
    "    \n",
    "    # Calculate features\n",
    "    features = transactions.join(profiles, \"customer_id\") \\\n",
    "        .groupBy(\"customer_id\") \\\n",
    "        .agg(\n",
    "            F.count(\"transaction_id\").alias(\"transaction_count\"),\n",
    "            F.sum(\"amount\").alias(\"total_spend\"),\n",
    "            F.avg(\"amount\").alias(\"avg_transaction\")\n",
    "        ) \\\n",
    "        .filter(F.col(\"transaction_count\") >= min_transactions)\n",
    "    \n",
    "    # Save output\n",
    "    features.write.mode(outputs[0]['mode']).saveAsTable(outputs[0]['table'])\n",
    "    \n",
    "    return features\n",
    "'''\n",
    "print(sample_function)\n",
    "\n",
    "# Run the pipeline\n",
    "print(\"\\n🚀 Running Customer Churn pipeline...\")\n",
    "# result = run_project(project=\"Customer Churn\", env=\"qat\")\n",
    "print(\"(Uncomment to run)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Custom Project: Supply Chain Optimization\n",
    "\n",
    "**Use Case:** Optimize inventory across warehouses and distribution centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Example: Supply Chain Optimization\n",
    "print(\"📦 Custom Example: Supply Chain Optimization\\n\")\n",
    "\n",
    "# Step 1: Initialize project\n",
    "result = initialize_project(\n",
    "    project_name=\"Supply Chain Optimization\",\n",
    "    project_type=\"custom\",\n",
    "    description=\"Inventory optimization across distribution network\"\n",
    ")\n",
    "\n",
    "print(f\"✅ Project created at: {result['project_path']}\\n\")\n",
    "\n",
    "# Step 2: Define custom entity hierarchy\n",
    "entity_mapping = {\n",
    "    \"entity_1\": \"region\",          # West, East, Central\n",
    "    \"entity_2\": \"warehouse\",       # Warehouse ID\n",
    "    \"entity_3\": \"product_category\" # Electronics, Apparel, etc.\n",
    "}\n",
    "\n",
    "print(\"Custom Entity Hierarchy:\")\n",
    "print(f\"  {entity_mapping['entity_1']} → {entity_mapping['entity_2']} → {entity_mapping['entity_3']}\")\n",
    "print(f\"  Example: West → WH-001 → Electronics\\n\")\n",
    "\n",
    "# Step 3: Update manifest with custom entities\n",
    "manifest_updates = {\n",
    "    \"entity_labels\": entity_mapping,\n",
    "    \"layer_order\": [\"Bronze\", \"Silver_Inventory\", \"Silver_Demand\", \"Gold_Optimization\"],\n",
    "    \"cache_plan\": {\n",
    "        \"Gold_Optimization\": [\"optimal_stock_levels\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Manifest Configuration:\")\n",
    "import json\n",
    "print(json.dumps(manifest_updates, indent=2))\n",
    "\n",
    "# Step 4: Add transformations to TransformationRegistry\n",
    "print(\"\\n\\nSample SQL to Add Transformations:\")\n",
    "sample_sql = \"\"\"\n",
    "INSERT INTO TransformationRegistry (\n",
    "    transformation_id, project, environment, layer,\n",
    "    entity_1, entity_2, entity_3,\n",
    "    module, function, inputs, outputs\n",
    ")\n",
    "VALUES (\n",
    "    'supply-west-wh001-inventory',\n",
    "    'supply chain optimization',\n",
    "    'qat',\n",
    "    'Silver_Inventory',\n",
    "    'West',\n",
    "    'WH-001',\n",
    "    'Electronics',\n",
    "    'supply_chain.transformations.inventory',\n",
    "    'calculate_current_stock',\n",
    "    '[\"qat_supply.inventory_bronze\", \"qat_supply.shipments_bronze\"]',\n",
    "    '[{\"table\": \"qat_supply.current_stock_silver\", \"mode\": \"overwrite\"}]'\n",
    ");\n",
    "\"\"\"\n",
    "print(sample_sql)\n",
    "\n",
    "# Step 5: Run the pipeline\n",
    "print(\"\\n🚀 Running Supply Chain pipeline...\")\n",
    "# result = run_project(project=\"Supply Chain Optimization\", env=\"qat\")\n",
    "print(\"(Configure transformations first, then uncomment to run)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Troubleshooting Guide {#5-troubleshooting}\n",
    "\n",
    "### 5.1 Common Issues and Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TROUBLESHOOTING GUIDE\n",
    "\n",
    "print(\"🔧 Common Issues and Solutions\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Issue 1: Manifest not found\n",
    "print(\"\\n❌ Issue 1: 'No manifest found for project'\")\n",
    "print(\"\\n✅ Solution:\")\n",
    "print(\"\"\"\n",
    "# Option A: Create manifest\n",
    "initialize_project(\"Project Name\", \"project_type\")\n",
    "\n",
    "# Option B: Specify path explicitly\n",
    "run_project(\n",
    "    project=\"Project Name\",\n",
    "    manifest_path=\"/path/to/manifest.json\"\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Issue 2: TransformationRegistry table not found\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\n❌ Issue 2: 'TransformationRegistry table does not exist'\")\n",
    "print(\"\\n✅ Solution:\")\n",
    "print(\"\"\"\n",
    "# Run the DDL script:\n",
    "# See: odibi_de_v2/sql/ddl/01_transformation_registry.sql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS TransformationRegistry (\n",
    "    transformation_id VARCHAR(100) PRIMARY KEY,\n",
    "    project VARCHAR(100) NOT NULL,\n",
    "    -- ... (see DDL file for complete schema)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Issue 3: JSON parsing error\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\n❌ Issue 3: 'Invalid JSON in inputs/constants/outputs'\")\n",
    "print(\"\\n✅ Solution:\")\n",
    "print(\"\"\"\n",
    "# ❌ WRONG:\n",
    "inputs: \"table1\"\n",
    "constants: \"threshold=100\"\n",
    "\n",
    "# ✅ CORRECT:\n",
    "inputs: '[\"table1\"]'                      # JSON array\n",
    "constants: '{\"threshold\": 100}'           # JSON object\n",
    "outputs: '[{\"table\": \"...\", \"mode\": \"overwrite\"}]'  # JSON array of objects\n",
    "\n",
    "# Validate JSON online: https://jsonlint.com/\n",
    "\"\"\")\n",
    "\n",
    "# Issue 4: Module not found\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\n❌ Issue 4: 'ModuleNotFoundError: No module named ...'\")\n",
    "print(\"\\n✅ Solution:\")\n",
    "print(\"\"\"\n",
    "# Check module path in TransformationRegistry\n",
    "# Ensure it matches your Python import structure\n",
    "\n",
    "# Example:\n",
    "# File: energy_efficiency/transformations/silver/functions.py\n",
    "# Module in DB: 'energy_efficiency.transformations.silver.functions'\n",
    "\n",
    "# Verify module exists:\n",
    "import importlib\n",
    "try:\n",
    "    mod = importlib.import_module('energy_efficiency.transformations.silver.functions')\n",
    "    print(\"✅ Module found\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"❌ Module not found: {e}\")\n",
    "\"\"\")\n",
    "\n",
    "# Issue 5: Function not found\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\n❌ Issue 5: 'Function ... does not exist in module'\")\n",
    "print(\"\\n✅ Solution:\")\n",
    "print(\"\"\"\n",
    "# Verify function exists in module:\n",
    "import importlib\n",
    "mod = importlib.import_module('silver.functions')\n",
    "if hasattr(mod, 'process_argo_boilers'):\n",
    "    print(\"✅ Function found\")\n",
    "else:\n",
    "    print(\"❌ Function not found\")\n",
    "    print(f\"Available functions: {dir(mod)}\")\n",
    "\"\"\")\n",
    "\n",
    "# Issue 6: Permission denied\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\n❌ Issue 6: 'Permission denied' or 'Authentication failed'\")\n",
    "print(\"\\n✅ Solution:\")\n",
    "print(\"\"\"\n",
    "# Use custom auth provider:\n",
    "def custom_auth(env, repo_path, logger_metadata):\n",
    "    # Your authentication logic\n",
    "    spark = get_authenticated_spark()\n",
    "    sql_provider = get_authenticated_sql()\n",
    "    return {\"spark\": spark, \"sql_provider\": sql_provider}\n",
    "\n",
    "run_project(\n",
    "    project=\"Project Name\",\n",
    "    env=\"qat\",\n",
    "    auth_provider=custom_auth\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Debugging Pipeline Failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUGGING PIPELINE FAILURES\n",
    "\n",
    "print(\"🐛 Debugging Pipeline Failures\\n\")\n",
    "\n",
    "# 1. Use health check utility\n",
    "print(\"1️⃣ Run Health Check\")\n",
    "print(\"\"\"\n",
    "from odibi_de_v2.utils import quick_health_check\n",
    "\n",
    "quick_health_check(\n",
    "    sql_provider=sql_provider,\n",
    "    spark=spark,\n",
    "    project=\"Energy Efficiency\",\n",
    "    env=\"qat\"\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# 2. Get recent failures\n",
    "print(\"\\n2️⃣ Check Recent Failures\")\n",
    "print(\"\"\"\n",
    "from odibi_de_v2.utils import get_failed_transformations\n",
    "\n",
    "failures = get_failed_transformations(\n",
    "    sql_provider=sql_provider,\n",
    "    project=\"Energy Efficiency\",\n",
    "    env=\"qat\",\n",
    "    hours_back=24\n",
    ")\n",
    "\n",
    "for failure in failures:\n",
    "    print(f\"Failed: {failure['transformation_id']}\")\n",
    "    print(f\"  Error: {failure['error_message']}\")\n",
    "\"\"\")\n",
    "\n",
    "# 3. Validate configuration\n",
    "print(\"\\n3️⃣ Validate Configuration\")\n",
    "print(\"\"\"\n",
    "from odibi_de_v2.config import validate_transformation_registry\n",
    "\n",
    "# Get configs from DB\n",
    "configs = sql_provider.execute_query(\n",
    "    \"SELECT * FROM TransformationRegistry WHERE project='Energy Efficiency'\"\n",
    ")\n",
    "\n",
    "# Validate\n",
    "result = validate_transformation_registry(configs)\n",
    "print(f\"Pass rate: {result.pass_rate:.1%}\")\n",
    "print(f\"Errors: {len(result.errors)}\")\n",
    "\"\"\")\n",
    "\n",
    "# 4. Run with verbose logging\n",
    "print(\"\\n4️⃣ Enable Verbose Logging\")\n",
    "print(\"\"\"\n",
    "result = run_project(\n",
    "    project=\"Energy Efficiency\",\n",
    "    env=\"qat\",\n",
    "    log_level=\"DEBUG\",  # More detailed logs\n",
    "    save_logs=True\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# 5. Test individual transformations\n",
    "print(\"\\n5️⃣ Test Individual Transformations\")\n",
    "print(\"\"\"\n",
    "# Import and test directly\n",
    "from silver.functions import process_argo_boilers\n",
    "\n",
    "result = process_argo_boilers(\n",
    "    spark=spark,\n",
    "    inputs=['qat_energy_efficiency.argo_boilers_bronze'],\n",
    "    constants={},\n",
    "    outputs=[{\"table\": \"test_output\", \"mode\": \"overwrite\"}]\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# 6. Check execution logs\n",
    "print(\"\\n6️⃣ Query Execution Logs\")\n",
    "print(\"\"\"\n",
    "# Check TransformationRunLog table\n",
    "logs = sql_provider.execute_query(\n",
    "    '''\n",
    "    SELECT TOP 10\n",
    "        transformation_id,\n",
    "        status,\n",
    "        error_message,\n",
    "        start_time,\n",
    "        end_time\n",
    "    FROM TransformationRunLog\n",
    "    WHERE project = 'Energy Efficiency'\n",
    "    ORDER BY start_time DESC\n",
    "    '''\n",
    ")\n",
    "display(logs)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n💡 See docs/troubleshooting.md for more debugging tips!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Performance Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORMANCE OPTIMIZATION TIPS\n",
    "\n",
    "print(\"⚡ Performance Optimization Tips\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Tip 1: Use caching for expensive operations\n",
    "print(\"\\n1️⃣ Smart Caching\")\n",
    "print(\"\"\"\n",
    "# Cache large intermediate tables\n",
    "cache_plan = {\n",
    "    \"Silver_2\": [\"large_joined_table\"],\n",
    "    \"Gold_1\": [\"expensive_aggregation\"]\n",
    "}\n",
    "\n",
    "run_project(\n",
    "    project=\"Energy Efficiency\",\n",
    "    env=\"qat\",\n",
    "    cache_plan=cache_plan\n",
    ")\n",
    "\n",
    "# Effect: Reduce recomputation, faster Gold layer execution\n",
    "\"\"\")\n",
    "\n",
    "# Tip 2: Parallel execution\n",
    "print(\"\\n2️⃣ Parallel Execution\")\n",
    "print(\"\"\"\n",
    "# Transformations with same 'step' run in parallel\n",
    "# Ensure independent transformations have same step number\n",
    "\n",
    "# Example TransformationRegistry:\n",
    "# transformation_id              layer      step\n",
    "# 'energy-argo-boilers'          Silver_1   1     ← Runs in parallel\n",
    "# 'energy-cedar-boilers'         Silver_1   1     ← Runs in parallel\n",
    "# 'energy-combined-boilers'      Gold_1     1     ← Runs after Silver_1\n",
    "\"\"\")\n",
    "\n",
    "# Tip 3: Layer-specific optimization\n",
    "print(\"\\n3️⃣ Layer-Specific Workers\")\n",
    "print(\"\"\"\n",
    "# In manifest.json:\n",
    "{\n",
    "  \"layers\": {\n",
    "    \"Silver_1\": {\n",
    "      \"max_workers\": 8  // More parallel workers\n",
    "    },\n",
    "    \"Gold_1\": {\n",
    "      \"max_workers\": 2  // Fewer workers for resource-intensive tasks\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Tip 4: Incremental processing\n",
    "print(\"\\n4️⃣ Incremental Processing\")\n",
    "print(\"\"\"\n",
    "# Use Delta Lake's MERGE for incremental updates\n",
    "# Instead of full table rewrites\n",
    "\n",
    "def incremental_transform(spark, inputs, outputs, **kwargs):\n",
    "    new_data = spark.table(inputs[0])\n",
    "    \n",
    "    spark.sql(f'''\n",
    "        MERGE INTO {outputs[0]['table']} target\n",
    "        USING new_data source\n",
    "        ON target.id = source.id\n",
    "        WHEN MATCHED THEN UPDATE SET *\n",
    "        WHEN NOT MATCHED THEN INSERT *\n",
    "    ''')\n",
    "\"\"\")\n",
    "\n",
    "# Tip 5: Partition pruning\n",
    "print(\"\\n5️⃣ Partition Pruning\")\n",
    "print(\"\"\"\n",
    "# Partition output tables by common filter columns\n",
    "{\n",
    "  \"table\": \"qat_energy.boilers_silver\",\n",
    "  \"mode\": \"overwrite\",\n",
    "  \"partition_by\": [\"date\", \"plant\"]  // Add partitioning\n",
    "}\n",
    "\n",
    "# Effect: Faster queries with WHERE date = '2024-01-01'\n",
    "\"\"\")\n",
    "\n",
    "# Tip 6: Z-ordering for Delta tables\n",
    "print(\"\\n6️⃣ Delta Lake Z-Ordering\")\n",
    "print(\"\"\"\n",
    "# Optimize Delta tables for common queries\n",
    "spark.sql('''\n",
    "    OPTIMIZE qat_energy.boilers_silver\n",
    "    ZORDER BY (plant, asset, date)\n",
    "''')\n",
    "\n",
    "# Effect: 10-100x faster queries on ordered columns\n",
    "\"\"\")\n",
    "\n",
    "# Tip 7: Monitor execution metrics\n",
    "print(\"\\n7️⃣ Monitor Execution Metrics\")\n",
    "print(\"\"\"\n",
    "from odibi_de_v2.utils import print_project_summary\n",
    "\n",
    "# View execution stats\n",
    "print_project_summary(\n",
    "    sql_provider=sql_provider,\n",
    "    spark=spark,\n",
    "    project=\"Energy Efficiency\",\n",
    "    env=\"qat\"\n",
    ")\n",
    "\n",
    "# Identify slow transformations and optimize\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\n💡 Typical performance improvements: 2-10x faster!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Quick Reference {#6-reference}\n",
    "\n",
    "### 6.1 Command Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUICK COMMAND REFERENCE\n",
    "\n",
    "print(\"\"\"\n",
    "📖 QUICK COMMAND REFERENCE\n",
    "==========================\n",
    "\n",
    "PROJECT MANAGEMENT\n",
    "------------------\n",
    "# Create new project\n",
    "initialize_project(\"Project Name\", \"manufacturing\")\n",
    "\n",
    "# Run full pipeline\n",
    "run_project(project=\"Project Name\", env=\"qat\")\n",
    "\n",
    "# Run specific layers\n",
    "run_project(project=\"Project Name\", env=\"qat\", target_layers=[\"Silver_1\"])\n",
    "\n",
    "# Dry run (validation only)\n",
    "run_project(project=\"Project Name\", env=\"qat\", dry_run=True)\n",
    "\n",
    "\n",
    "HEALTH & DIAGNOSTICS\n",
    "--------------------\n",
    "from odibi_de_v2.utils import quick_health_check, print_project_summary\n",
    "\n",
    "# Quick health check\n",
    "quick_health_check(sql_provider, spark, \"Project Name\", \"qat\")\n",
    "\n",
    "# Project summary\n",
    "print_project_summary(sql_provider, spark, \"Project Name\", \"qat\")\n",
    "\n",
    "# List all projects\n",
    "from odibi_de_v2.utils import list_projects\n",
    "projects = list_projects(sql_provider, env=\"qat\")\n",
    "\n",
    "\n",
    "CONFIGURATION\n",
    "-------------\n",
    "from odibi_de_v2.config import TransformationRegistryUI\n",
    "\n",
    "# Interactive config editor\n",
    "ui = TransformationRegistryUI(project=\"Project Name\", env=\"qat\")\n",
    "ui.render()\n",
    "\n",
    "# Validate configurations\n",
    "from odibi_de_v2.config import validate_transformation_registry\n",
    "result = validate_transformation_registry(configs)\n",
    "\n",
    "\n",
    "DEBUGGING\n",
    "---------\n",
    "from odibi_de_v2.utils import get_failed_transformations\n",
    "\n",
    "# Get recent failures\n",
    "failures = get_failed_transformations(\n",
    "    sql_provider, \"Project Name\", \"qat\", hours_back=24\n",
    ")\n",
    "\n",
    "# Retry failed transformations\n",
    "from odibi_de_v2.utils import retry_failed_transformations\n",
    "retry_failed_transformations(sql_provider, spark, \"Project Name\", \"qat\")\n",
    "\n",
    "\n",
    "IMPORTS\n",
    "-------\n",
    "from odibi_de_v2 import run_project, initialize_project\n",
    "from odibi_de_v2.utils import (\n",
    "    quick_health_check,\n",
    "    print_project_summary,\n",
    "    list_projects,\n",
    "    get_failed_transformations,\n",
    "    retry_failed_transformations\n",
    ")\n",
    "from odibi_de_v2.config import (\n",
    "    TransformationRegistryUI,\n",
    "    validate_transformation_registry\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 SQL DDL Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL DDL REFERENCE\n",
    "\n",
    "print(\"\"\"\n",
    "📋 SQL DDL REFERENCE\n",
    "====================\n",
    "\n",
    "TRANSFORMATIONREGISTRY TABLE\n",
    "----------------------------\n",
    "\"\"\")\n",
    "\n",
    "ddl_transformation_registry = '''\n",
    "CREATE TABLE IF NOT EXISTS TransformationRegistry (\n",
    "    -- Primary identification\n",
    "    transformation_id VARCHAR(100) PRIMARY KEY,\n",
    "    transformation_group_id VARCHAR(100),\n",
    "    \n",
    "    -- Project and environment scoping\n",
    "    project VARCHAR(100) NOT NULL,\n",
    "    environment VARCHAR(20) NOT NULL DEFAULT 'qat',\n",
    "    \n",
    "    -- Layer and execution control\n",
    "    layer VARCHAR(50) NOT NULL,\n",
    "    step INT NOT NULL DEFAULT 1,\n",
    "    enabled BIT NOT NULL DEFAULT 1,\n",
    "    \n",
    "    -- Generic entity hierarchy\n",
    "    entity_1 VARCHAR(100),\n",
    "    entity_2 VARCHAR(100),\n",
    "    entity_3 VARCHAR(100),\n",
    "    \n",
    "    -- Transformation logic\n",
    "    module VARCHAR(255) NOT NULL,\n",
    "    function VARCHAR(255) NOT NULL,\n",
    "    \n",
    "    -- Flexible I/O (JSON)\n",
    "    inputs NVARCHAR(MAX),\n",
    "    constants NVARCHAR(MAX),\n",
    "    outputs NVARCHAR(MAX),\n",
    "    \n",
    "    -- Metadata\n",
    "    description NVARCHAR(500),\n",
    "    created_at DATETIME DEFAULT GETDATE(),\n",
    "    updated_at DATETIME DEFAULT GETDATE(),\n",
    "    created_by VARCHAR(100),\n",
    "    updated_by VARCHAR(100),\n",
    "    \n",
    "    -- Indexes\n",
    "    INDEX idx_project_env_layer (project, environment, layer),\n",
    "    INDEX idx_enabled (enabled),\n",
    "    INDEX idx_transformation_group (transformation_group_id)\n",
    ");\n",
    "'''\n",
    "\n",
    "print(ddl_transformation_registry)\n",
    "\n",
    "print(\"\"\"\n",
    "\n",
    "SAMPLE INSERT STATEMENT\n",
    "-----------------------\n",
    "\"\"\")\n",
    "\n",
    "sample_insert = '''\n",
    "INSERT INTO TransformationRegistry (\n",
    "    transformation_id,\n",
    "    project,\n",
    "    environment,\n",
    "    layer,\n",
    "    entity_1,\n",
    "    entity_2,\n",
    "    module,\n",
    "    function,\n",
    "    inputs,\n",
    "    constants,\n",
    "    outputs,\n",
    "    description\n",
    ")\n",
    "VALUES (\n",
    "    'my-transformation-id',\n",
    "    'my project',\n",
    "    'qat',\n",
    "    'Silver_1',\n",
    "    'EntityA',\n",
    "    'EntityB',\n",
    "    'my_project.transformations.silver',\n",
    "    'my_function',\n",
    "    '[\"input_table1\", \"input_table2\"]',\n",
    "    '{\"threshold\": 100, \"window_days\": 30}',\n",
    "    '[{\"table\": \"output_table\", \"mode\": \"overwrite\"}]',\n",
    "    'My transformation description'\n",
    ");\n",
    "'''\n",
    "\n",
    "print(sample_insert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Manifest Schema Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANIFEST SCHEMA REFERENCE\n",
    "\n",
    "print(\"\"\"\n",
    "📄 MANIFEST SCHEMA REFERENCE\n",
    "============================\n",
    "\n",
    "Complete manifest.json structure:\n",
    "\"\"\")\n",
    "\n",
    "manifest_schema = {\n",
    "    \"project_name\": \"str - Project name\",\n",
    "    \"project_type\": \"str - manufacturing|analytics|ml_pipeline|custom\",\n",
    "    \"description\": \"str - Project description\",\n",
    "    \"version\": \"str - Semantic version (e.g., 1.0.0)\",\n",
    "    \n",
    "    \"layer_order\": [\n",
    "        \"Array of layer names in execution order\",\n",
    "        \"Example: ['Bronze', 'Silver_1', 'Silver_2', 'Gold_1']\"\n",
    "    ],\n",
    "    \n",
    "    \"layers\": {\n",
    "        \"LayerName\": {\n",
    "            \"name\": \"str - Layer name\",\n",
    "            \"description\": \"str - Layer description\",\n",
    "            \"depends_on\": [\"Array of prerequisite layers\"],\n",
    "            \"cache_tables\": [\"Array of table names to cache\"],\n",
    "            \"max_workers\": \"int|null - Max parallel workers\"\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"environments\": [\n",
    "        \"Array of supported environments\",\n",
    "        \"Example: ['dev', 'qat', 'prod']\"\n",
    "    ],\n",
    "    \"default_env\": \"str - Default environment\",\n",
    "    \n",
    "    \"entity_labels\": {\n",
    "        \"entity_1\": \"str - Label for entity_1 (e.g., 'plant')\",\n",
    "        \"entity_2\": \"str - Label for entity_2 (e.g., 'asset')\",\n",
    "        \"entity_3\": \"str - Label for entity_3 (e.g., 'equipment')\"\n",
    "    },\n",
    "    \n",
    "    \"transformation_modules\": [\n",
    "        \"Array of Python module paths\",\n",
    "        \"Example: ['energy_efficiency.transformations']\"\n",
    "    ],\n",
    "    \n",
    "    \"cache_plan\": {\n",
    "        \"LayerName\": [\n",
    "            \"Array of table names to cache for this layer\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"owner\": \"str|null - Project owner\",\n",
    "    \"tags\": [\"Array of tags for categorization\"],\n",
    "    \"metadata\": {\"object - Custom metadata key-value pairs\"}\n",
    "}\n",
    "\n",
    "import json\n",
    "print(json.dumps(manifest_schema, indent=2))\n",
    "\n",
    "print(\"\"\"\n",
    "\n",
    "💡 Use initialize_project() to generate a valid manifest!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎓 Summary\n",
    "\n",
    "**Congratulations!** You've completed the odibi_de_v2 Framework Evolution Tutorial.\n",
    "\n",
    "### What You've Learned:\n",
    "\n",
    "1. ✅ **Evolution Story**: Why v1.x → v2.0 and key benefits\n",
    "2. ✅ **Architecture**: TransformationRegistry, Manifests, Component interaction\n",
    "3. ✅ **Core APIs**: `initialize_project()` and `run_project()`\n",
    "4. ✅ **Configuration**: TransformationRegistry UI and validation\n",
    "5. ✅ **Migration**: Step-by-step v1.x → v2.0 migration\n",
    "6. ✅ **Advanced Patterns**: Multi-env, caching, custom auth\n",
    "7. ✅ **Industry Examples**: Manufacturing, Analytics, Custom domains\n",
    "8. ✅ **Troubleshooting**: Common issues, debugging, performance tips\n",
    "9. ✅ **Reference**: Commands, SQL DDL, Manifest schema\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Try it yourself**: Create a new project with `initialize_project()`\n",
    "2. **Migrate existing projects**: Follow the migration guide in Cell 7\n",
    "3. **Read the docs**: See `MIGRATION_GUIDE.md`, `QOL_UTILITIES_SUMMARY.md`, `QUICK_REFERENCE.md`\n",
    "4. **Join the community**: Share your experience and help others\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- 📖 **Full Documentation**: `/d:/projects/odibi_de_v2/docs/`\n",
    "- 🔀 **Migration Guide**: `MIGRATION_GUIDE.md`\n",
    "- ⚡ **Quick Reference**: `QUICK_REFERENCE.md`\n",
    "- 🛠️ **Quality of Life Utilities**: `QOL_UTILITIES_SUMMARY.md`\n",
    "- 💻 **GitHub**: [Your Repository URL]\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Engineering! 🚀**\n",
    "\n",
    "*odibi_de_v2 v2.0 - Universal Data Engineering Framework*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
